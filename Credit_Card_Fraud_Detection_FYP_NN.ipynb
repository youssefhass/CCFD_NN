{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and store the dataset\n",
    "dataf = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. use shuffle/ randomize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2. use One-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3. use Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. use data spletting up X/y Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5. use conver data_frame to numpy arrays (float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6. use spletting the final data into X/y train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = dataf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (shuffled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data = pd.get_dummies(shuffled_data, columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(one_hot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = (one_hot_data - one_hot_data.min()) / (one_hot_data.max() - one_hot_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = normalized_data.drop(['Class_0', 'Class_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = normalized_data[['Class_0', 'Class_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. Spletting up X/y Values\n",
    "ar_X, ar_y = np.asarray(df_X.values, dtype ='float32'), np.asarray(df_y.values, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allocate first 80% of data_frames into training data and remining 20% to testing data\n",
    "train_size = int(0.8 * len(ar_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_X_train, raw_y_train) = (ar_X[:train_size], ar_y[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_X_test, raw_y_test) = (ar_X[train_size:], ar_y[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_legit, count_fraud = np.unique(dataf['Class'], return_counts=True) [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_ratio = (count_fraud / (count_legit + count_fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of fraudulent transactions: 0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "print('Percent of fraudulent transactions:', fraud_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies a logit weighting of 578 (1/0.0017) to fraudulent transactions to cause model to pay more attention to them\n",
    "weighting = 1 / fraud_ratio\n",
    "raw_y_train[:, 1] = raw_y_train[:, 1] * weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing older version of tensorflow as new version does not support GPU on macbook.\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 cells for the input dimensions\n",
    "input_dimensions = ar_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 cells for the output dimensions \n",
    "output_dimensions = ar_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 cells for the 1st layer\n",
    "num_layer_1_cells = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 150 cells for the second layer\n",
    "num_layer_2_cells = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/youssef/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#to fix an issue with tf 2.0 \n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "#with tf.Session() as sess:\n",
    "# We will use these as inputs to the model when it comes time to train it (assign values at run time)\n",
    "X_train_node = tf.placeholder(tf.float32, [None, input_dimensions], name='X_train')\n",
    "y_train_node = tf.placeholder(tf.float32, [None, output_dimensions], name='y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use these as inputs to the model once it comes time to test it\n",
    "X_test_node = tf.constant(raw_X_test, name='X_test')\n",
    "y_test_node = tf.constant(raw_y_test, name='y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer takes in input and passes output to 2nd layer\n",
    "weight_1_node = tf.Variable(tf.zeros([input_dimensions, num_layer_1_cells]), name='weight_1')\n",
    "biases_1_node = tf.Variable(tf.zeros([num_layer_1_cells]), name='biases_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second layer takes in input from 1st layer and passes output to 3rd layer\n",
    "weight_2_node = tf.Variable(tf.zeros([num_layer_1_cells, num_layer_2_cells]), name='weight_2')\n",
    "biases_2_node = tf.Variable(tf.zeros([num_layer_2_cells]), name='biases_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third layer takes in input from 2nd layer and outputs [1 0] or [0 1] depending on fraud vs legit\n",
    "weight_3_node = tf.Variable(tf.zeros([num_layer_2_cells, output_dimensions]), name='weight_3')\n",
    "biases_3_node = tf.Variable(tf.zeros([output_dimensions]), name='biases_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run an input tensor through the 3 layers and output a tensor that will give us a fraud/legit result\n",
    "# Each layer uses a different function to fit lines through the data and predict whether a given input tensor will \\\n",
    "#   result in a fraudulent or legitimate transaction\n",
    "def network(input_tensor):\n",
    "    # Sigmoid fits modified data well\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(input_tensor, weight_1_node) + biases_1_node)\n",
    "    # Dropout prevents model from becoming lazy and over confident\n",
    "    layer2 = tf.nn.dropout(tf.nn.sigmoid(tf.matmul(layer1, weight_2_node) + biases_2_node), 0.85)\n",
    "    # Softmax works very well with one hot encoding which is how results are outputted\n",
    "    layer3 = tf.nn.softmax(tf.matmul(layer2, weight_3_node) + biases_3_node)\n",
    "    return layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-7127a61d0022>:8: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Used to predict what results will be given training or testing input data\n",
    "# Remember, X_train_node is just a placeholder for now. We will enter values at run time\n",
    "y_train_prediction = network(X_train_node)\n",
    "y_test_prediction = network(X_test_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy loss function measures differences between actual output and predicted output\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(y_train_node, y_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer function will try to minimize loss (cross_entropy) but changing the 3 layers' variable values at a\n",
    "#   learning rate of 0.005\n",
    "optimizer = tf.train.AdamOptimizer(0.005).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of the actual result vs the predicted result\n",
    "def calculate_accuracy(actual, predicted):\n",
    "    actual = np.argmax(actual, 1)\n",
    "    predicted = np.argmax(predicted, 1)\n",
    "    return (100 * np.sum(np.equal(predicted, actual)) / predicted.shape[0])\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Current loss: 1.3999 Elapsed time: 0.79 seconds\n",
      "Current accuracy: 0.16%\n",
      "Epoch: 10 Current loss: 1.3982 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 9.08%\n",
      "Epoch: 20 Current loss: 1.3797 Elapsed time: 0.67 seconds\n",
      "Current accuracy: 0.88%\n",
      "Epoch: 30 Current loss: 1.2868 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 66.78%\n",
      "Epoch: 40 Current loss: 1.1216 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 96.48%\n",
      "Epoch: 50 Current loss: 1.0005 Elapsed time: 0.69 seconds\n",
      "Current accuracy: 98.54%\n",
      "Epoch: 60 Current loss: 0.9232 Elapsed time: 0.67 seconds\n",
      "Current accuracy: 99.21%\n",
      "Epoch: 70 Current loss: 0.8899 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 99.50%\n",
      "Epoch: 80 Current loss: 0.8717 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 99.60%\n",
      "Epoch: 90 Current loss: 0.8589 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 99.71%\n",
      "Final accuracy: 99.36%\n",
      "Final fraud specific accuracy: 86.67%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        _, cross_entropy_score = session.run([optimizer, cross_entropy],\n",
    "                                             feed_dict={X_train_node: raw_X_train, y_train_node: raw_y_train})\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            timer = time.time() - start_time\n",
    "\n",
    "            print('Epoch: {}'.format(epoch), 'Current loss: {0:.4f}'.format(cross_entropy_score),\n",
    "                  'Elapsed time: {0:.2f} seconds'.format(timer))\n",
    "\n",
    "            final_y_test = y_test_node.eval()\n",
    "            final_y_test_prediction = y_test_prediction.eval()\n",
    "            final_accuracy = calculate_accuracy(final_y_test, final_y_test_prediction)\n",
    "            print(\"Current accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "    final_y_test = y_test_node.eval()\n",
    "    final_y_test_prediction = y_test_prediction.eval()\n",
    "    final_accuracy = calculate_accuracy(final_y_test, final_y_test_prediction)\n",
    "    print(\"Final accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "final_fraud_y_test = final_y_test[final_y_test[:, 1] == 1]\n",
    "final_fraud_y_test_prediction = final_y_test_prediction[final_y_test[:, 1] == 1]\n",
    "final_fraud_accuracy = calculate_accuracy(final_fraud_y_test, final_fraud_y_test_prediction)\n",
    "print('Final fraud specific accuracy: {0:.2f}%'.format(final_fraud_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
