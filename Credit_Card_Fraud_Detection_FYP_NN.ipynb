{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and store the dataset\n",
    "dataf = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time         V1         V2        V3        V4        V5  \\\n",
      "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
      "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
      "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
      "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
      "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...       V21       V22  \\\n",
      "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
      "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
      "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
      "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
      "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
      "...          ...       ...       ...       ...  ...       ...       ...   \n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
      "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
      "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
      "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
      "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
      "...          ...       ...       ...       ...       ...       ...     ...   \n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[284807 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. use shuffle/ randomize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2. use One-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3. use Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. use data spletting up X/y Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5. use conver data_frame to numpy arrays (float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6. use spletting the final data into X/y train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = dataf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "180478  124558.0  0.241035 -0.250145 -0.091440 -2.107549  0.316241 -0.188321   \n",
      "131186   79516.0  1.131067  0.218758  0.457257  0.952148 -0.129001 -0.089778   \n",
      "38429    39392.0 -2.321250 -1.219581  0.930051 -2.076673 -3.028028 -0.078242   \n",
      "151637   95843.0 -0.220328  0.527158  1.202717 -0.308179  0.418326  0.526265   \n",
      "39382    39812.0 -0.442866  1.601341 -0.003082  0.807294  0.281344 -1.147997   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "18766    29748.0 -0.054077  0.879381  1.047447  1.230234 -0.552576 -0.060046   \n",
      "115694   73977.0  1.199786 -0.009766  1.042385  0.730794 -1.095117 -0.939522   \n",
      "144402   86094.0  1.213241  0.221841  0.253828  0.654688 -0.290083 -0.631325   \n",
      "39660    39916.0 -1.089013  0.042329  2.633816 -0.930363 -0.470014  0.395950   \n",
      "82646    59488.0 -1.880744 -0.082001  0.720805  0.312479  0.211554 -1.068624   \n",
      "\n",
      "              V7        V8        V9  ...       V21       V22       V23  \\\n",
      "180478  0.546295 -0.196081 -0.921660  ... -0.037260 -0.166486  0.165024   \n",
      "131186 -0.053570  0.090556 -0.225878  ...  0.031457  0.102703 -0.011243   \n",
      "38429  -0.015673  0.716913 -2.779004  ...  0.181876  0.260303 -0.068534   \n",
      "151637  0.115475  0.111257  1.917103  ...  0.141319  0.775038 -0.274439   \n",
      "39382   1.083691 -0.292449 -0.097588  ...  0.015364  0.646284 -0.010997   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "18766  -0.042578 -1.784364 -0.129780  ...  1.332870 -0.953852 -0.217231   \n",
      "115694 -0.407399 -0.023213  0.525860  ... -0.077585 -0.276199  0.146093   \n",
      "144402 -0.072051  0.002197  0.208169  ... -0.273906 -0.812281  0.173510   \n",
      "39660   0.218863  0.376673  0.142642  ... -0.030389 -0.072791  0.005492   \n",
      "82646   0.449240 -0.088648 -0.355390  ... -0.243709  0.030843  0.982655   \n",
      "\n",
      "             V24       V25       V26       V27       V28  Amount  Class  \n",
      "180478  0.215811 -0.462951 -0.553542 -0.272597 -0.266875   47.90      0  \n",
      "131186  0.015306  0.440301 -0.427848  0.034206  0.013764   12.58      0  \n",
      "38429   0.536688  0.325211 -0.234070 -0.167817 -0.291091  370.00      0  \n",
      "151637 -0.003682 -0.196291 -0.150648  0.168394  0.173127   23.45      0  \n",
      "39382   0.404162 -0.622792 -0.462301  0.212708 -0.165827    9.99      0  \n",
      "...          ...       ...       ...       ...       ...     ...    ...  \n",
      "18766   0.402405  0.807069 -0.370136  0.281773  0.220764   91.95      0  \n",
      "115694  0.700708  0.079409  0.196662 -0.013362  0.027583    6.47      0  \n",
      "144402  0.001469  0.103393  0.128141 -0.014238  0.024780    1.29      0  \n",
      "39660   0.293203  0.071776  0.853977 -0.031247  0.052831   79.54      0  \n",
      "82646   0.548921 -0.301341  0.017837 -0.550271 -0.250452   30.00      0  \n",
      "\n",
      "[284807 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print (shuffled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data = pd.get_dummies(shuffled_data, columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "180478  124558.0  0.241035 -0.250145 -0.091440 -2.107549  0.316241 -0.188321   \n",
      "131186   79516.0  1.131067  0.218758  0.457257  0.952148 -0.129001 -0.089778   \n",
      "38429    39392.0 -2.321250 -1.219581  0.930051 -2.076673 -3.028028 -0.078242   \n",
      "151637   95843.0 -0.220328  0.527158  1.202717 -0.308179  0.418326  0.526265   \n",
      "39382    39812.0 -0.442866  1.601341 -0.003082  0.807294  0.281344 -1.147997   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "18766    29748.0 -0.054077  0.879381  1.047447  1.230234 -0.552576 -0.060046   \n",
      "115694   73977.0  1.199786 -0.009766  1.042385  0.730794 -1.095117 -0.939522   \n",
      "144402   86094.0  1.213241  0.221841  0.253828  0.654688 -0.290083 -0.631325   \n",
      "39660    39916.0 -1.089013  0.042329  2.633816 -0.930363 -0.470014  0.395950   \n",
      "82646    59488.0 -1.880744 -0.082001  0.720805  0.312479  0.211554 -1.068624   \n",
      "\n",
      "              V7        V8        V9  ...       V22       V23       V24  \\\n",
      "180478  0.546295 -0.196081 -0.921660  ... -0.166486  0.165024  0.215811   \n",
      "131186 -0.053570  0.090556 -0.225878  ...  0.102703 -0.011243  0.015306   \n",
      "38429  -0.015673  0.716913 -2.779004  ...  0.260303 -0.068534  0.536688   \n",
      "151637  0.115475  0.111257  1.917103  ...  0.775038 -0.274439 -0.003682   \n",
      "39382   1.083691 -0.292449 -0.097588  ...  0.646284 -0.010997  0.404162   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "18766  -0.042578 -1.784364 -0.129780  ... -0.953852 -0.217231  0.402405   \n",
      "115694 -0.407399 -0.023213  0.525860  ... -0.276199  0.146093  0.700708   \n",
      "144402 -0.072051  0.002197  0.208169  ... -0.812281  0.173510  0.001469   \n",
      "39660   0.218863  0.376673  0.142642  ... -0.072791  0.005492  0.293203   \n",
      "82646   0.449240 -0.088648 -0.355390  ...  0.030843  0.982655  0.548921   \n",
      "\n",
      "             V25       V26       V27       V28  Amount  Class_0  Class_1  \n",
      "180478 -0.462951 -0.553542 -0.272597 -0.266875   47.90        1        0  \n",
      "131186  0.440301 -0.427848  0.034206  0.013764   12.58        1        0  \n",
      "38429   0.325211 -0.234070 -0.167817 -0.291091  370.00        1        0  \n",
      "151637 -0.196291 -0.150648  0.168394  0.173127   23.45        1        0  \n",
      "39382  -0.622792 -0.462301  0.212708 -0.165827    9.99        1        0  \n",
      "...          ...       ...       ...       ...     ...      ...      ...  \n",
      "18766   0.807069 -0.370136  0.281773  0.220764   91.95        1        0  \n",
      "115694  0.079409  0.196662 -0.013362  0.027583    6.47        1        0  \n",
      "144402  0.103393  0.128141 -0.014238  0.024780    1.29        1        0  \n",
      "39660   0.071776  0.853977 -0.031247  0.052831   79.54        1        0  \n",
      "82646  -0.301341  0.017837 -0.550271 -0.250452   30.00        1        0  \n",
      "\n",
      "[284807 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = (one_hot_data - one_hot_data.min()) / (one_hot_data.max() - one_hot_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "180478  0.720855  0.962389  0.764619  0.835829  0.158504  0.767845  0.261126   \n",
      "131186  0.460183  0.977509  0.769567  0.845337  0.294138  0.764848  0.262117   \n",
      "38429   0.227974  0.918859  0.754390  0.853530  0.159873  0.745332  0.262233   \n",
      "151637  0.554673  0.954551  0.772821  0.858255  0.238269  0.768532  0.268311   \n",
      "39382   0.230404  0.950770  0.784155  0.837360  0.287717  0.767610  0.251478   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "18766   0.172161  0.957375  0.776537  0.855564  0.306465  0.761996  0.262416   \n",
      "115694  0.428127  0.978677  0.767155  0.855477  0.284326  0.758344  0.253574   \n",
      "144402  0.498252  0.978905  0.769599  0.841812  0.280952  0.763763  0.256672   \n",
      "39660   0.231006  0.939793  0.767705  0.883054  0.210688  0.762552  0.267001   \n",
      "82646   0.344275  0.926342  0.766393  0.849904  0.265782  0.767140  0.252276   \n",
      "\n",
      "              V7        V8        V9  ...       V22       V23       V24  \\\n",
      "180478  0.268684  0.783282  0.431030  ...  0.502264  0.667884  0.411315   \n",
      "131186  0.265029  0.786357  0.454999  ...  0.514822  0.665267  0.384297   \n",
      "38429   0.265260  0.793076  0.367048  ...  0.522174  0.664416  0.454553   \n",
      "151637  0.266059  0.786579  0.528821  ...  0.546187  0.661358  0.381738   \n",
      "39382   0.271957  0.782248  0.459418  ...  0.540180  0.665270  0.436695   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "18766   0.265096  0.766245  0.458309  ...  0.465534  0.662208  0.436458   \n",
      "115694  0.262874  0.785136  0.480895  ...  0.497146  0.667603  0.476654   \n",
      "144402  0.264917  0.785409  0.469951  ...  0.472138  0.668010  0.382432   \n",
      "39660   0.266689  0.789426  0.467694  ...  0.506635  0.665515  0.421743   \n",
      "82646   0.268092  0.784435  0.450537  ...  0.511470  0.680027  0.456201   \n",
      "\n",
      "             V25       V26       V27       V28    Amount  Class_0  Class_1  \n",
      "180478  0.551920  0.335028  0.411479  0.307708  0.001864      1.0      0.0  \n",
      "131186  0.602622  0.355560  0.417142  0.313403  0.000490      1.0      0.0  \n",
      "38429   0.596161  0.387213  0.413413  0.307217  0.014402      1.0      0.0  \n",
      "151637  0.566888  0.400840  0.419619  0.316637  0.000913      1.0      0.0  \n",
      "39382   0.542948  0.349932  0.420437  0.309759  0.000389      1.0      0.0  \n",
      "...          ...       ...       ...       ...       ...      ...      ...  \n",
      "18766   0.623209  0.364987  0.421712  0.317604  0.003579      1.0      0.0  \n",
      "115694  0.582364  0.457573  0.416264  0.313684  0.000252      1.0      0.0  \n",
      "144402  0.583710  0.446380  0.416248  0.313627  0.000050      1.0      0.0  \n",
      "39660   0.581936  0.564944  0.415934  0.314196  0.003096      1.0      0.0  \n",
      "82646   0.560992  0.428362  0.406354  0.308041  0.001168      1.0      0.0  \n",
      "\n",
      "[284807 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = normalized_data.drop(['Class_0', 'Class_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = normalized_data[['Class_0', 'Class_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. Spletting up X/y Values\n",
    "ar_X, ar_y = np.asarray(df_X.values, dtype ='float32'), np.asarray(df_y.values, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allocate first 80% of data_frames into training data and remining 20% to testing data\n",
    "train_size = int(0.8 * len(ar_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_X_train, raw_y_train) = (ar_X[:train_size], ar_y[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_X_test, raw_y_test) = (ar_X[train_size:], ar_y[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_legit, count_fraud = np.unique(dataf['Class'], return_counts=True) [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_ratio = (count_fraud / (count_legit + count_fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of fraudulent transactions: 0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "print('Percent of fraudulent transactions:', fraud_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies a logit weighting of 578 (1/0.0017) to fraudulent transactions to cause model to pay more attention to them\n",
    "weighting = 1 / fraud_ratio\n",
    "raw_y_train[:, 1] = raw_y_train[:, 1] * weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing older version of tensorflow as new version does not support GPU on macbook.\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 cells for the input dimensions\n",
    "input_dimensions = ar_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 cells for the output dimensions \n",
    "output_dimensions = ar_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 cells for the 1st layer\n",
    "num_layer_1_cells = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 150 cells for the second layer\n",
    "num_layer_2_cells = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/youssef/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#to fix an issue with tf 2.0 \n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "#with tf.Session() as sess:\n",
    "# We will use these as inputs to the model when it comes time to train it (assign values at run time)\n",
    "X_train_node = tf.placeholder(tf.float32, [None, input_dimensions], name='X_train')\n",
    "y_train_node = tf.placeholder(tf.float32, [None, output_dimensions], name='y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use these as inputs to the model once it comes time to test it\n",
    "X_test_node = tf.constant(raw_X_test, name='X_test')\n",
    "y_test_node = tf.constant(raw_y_test, name='y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer takes in input and passes output to 2nd layer\n",
    "weight_1_node = tf.Variable(tf.zeros([input_dimensions, num_layer_1_cells]), name='weight_1')\n",
    "biases_1_node = tf.Variable(tf.zeros([num_layer_1_cells]), name='biases_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second layer takes in input from 1st layer and passes output to 3rd layer\n",
    "weight_2_node = tf.Variable(tf.zeros([num_layer_1_cells, num_layer_2_cells]), name='weight_2')\n",
    "biases_2_node = tf.Variable(tf.zeros([num_layer_2_cells]), name='biases_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third layer takes in input from 2nd layer and outputs [1 0] or [0 1] depending on fraud vs legit\n",
    "weight_3_node = tf.Variable(tf.zeros([num_layer_2_cells, output_dimensions]), name='weight_3')\n",
    "biases_3_node = tf.Variable(tf.zeros([output_dimensions]), name='biases_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run an input tensor through the 3 layers and output a tensor that will give us a fraud/legit result\n",
    "# Each layer uses a different function to fit lines through the data and predict whether a given input tensor will \\\n",
    "#   result in a fraudulent or legitimate transaction\n",
    "def network(input_tensor):\n",
    "    # Sigmoid fits modified data well\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(input_tensor, weight_1_node) + biases_1_node)\n",
    "    # Dropout prevents model from becoming lazy and over confident\n",
    "    layer2 = tf.nn.dropout(tf.nn.sigmoid(tf.matmul(layer1, weight_2_node) + biases_2_node), 0.85)\n",
    "    # Softmax works very well with one hot encoding which is how results are outputted\n",
    "    layer3 = tf.nn.softmax(tf.matmul(layer2, weight_3_node) + biases_3_node)\n",
    "    return layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-7127a61d0022>:8: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Used to predict what results will be given training or testing input data\n",
    "# Remember, X_train_node is just a placeholder for now. We will enter values at run time\n",
    "y_train_prediction = network(X_train_node)\n",
    "y_test_prediction = network(X_test_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy loss function measures differences between actual output and predicted output\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(y_train_node, y_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer function will try to minimize loss (cross_entropy) but changing the 3 layers' variable values at a\n",
    "#   learning rate of 0.005\n",
    "optimizer = tf.train.AdamOptimizer(0.005).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of the actual result vs the predicted result\n",
    "def calculate_accuracy(actual, predicted):\n",
    "    actual = np.argmax(actual, 1)\n",
    "    predicted = np.argmax(predicted, 1)\n",
    "    return (100 * np.sum(np.equal(predicted, actual)) / predicted.shape[0])\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Current loss: 1.3999 Elapsed time: 0.79 seconds\n",
      "Current accuracy: 0.16%\n",
      "Epoch: 10 Current loss: 1.3982 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 9.08%\n",
      "Epoch: 20 Current loss: 1.3797 Elapsed time: 0.67 seconds\n",
      "Current accuracy: 0.88%\n",
      "Epoch: 30 Current loss: 1.2868 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 66.78%\n",
      "Epoch: 40 Current loss: 1.1216 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 96.48%\n",
      "Epoch: 50 Current loss: 1.0005 Elapsed time: 0.69 seconds\n",
      "Current accuracy: 98.54%\n",
      "Epoch: 60 Current loss: 0.9232 Elapsed time: 0.67 seconds\n",
      "Current accuracy: 99.21%\n",
      "Epoch: 70 Current loss: 0.8899 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 99.50%\n",
      "Epoch: 80 Current loss: 0.8717 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 99.60%\n",
      "Epoch: 90 Current loss: 0.8589 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 99.71%\n",
      "Final accuracy: 99.36%\n",
      "Final fraud specific accuracy: 86.67%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        _, cross_entropy_score = session.run([optimizer, cross_entropy],\n",
    "                                             feed_dict={X_train_node: raw_X_train, y_train_node: raw_y_train})\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            timer = time.time() - start_time\n",
    "\n",
    "            print('Epoch: {}'.format(epoch), 'Current loss: {0:.4f}'.format(cross_entropy_score),\n",
    "                  'Elapsed time: {0:.2f} seconds'.format(timer))\n",
    "\n",
    "            final_y_test = y_test_node.eval()\n",
    "            final_y_test_prediction = y_test_prediction.eval()\n",
    "            final_accuracy = calculate_accuracy(final_y_test, final_y_test_prediction)\n",
    "            print(\"Current accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "    final_y_test = y_test_node.eval()\n",
    "    final_y_test_prediction = y_test_prediction.eval()\n",
    "    final_accuracy = calculate_accuracy(final_y_test, final_y_test_prediction)\n",
    "    print(\"Final accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "final_fraud_y_test = final_y_test[final_y_test[:, 1] == 1]\n",
    "final_fraud_y_test_prediction = final_y_test_prediction[final_y_test[:, 1] == 1]\n",
    "final_fraud_accuracy = calculate_accuracy(final_fraud_y_test, final_fraud_y_test_prediction)\n",
    "print('Final fraud specific accuracy: {0:.2f}%'.format(final_fraud_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
