{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and store the dataset\n",
    "dataf = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time         V1         V2        V3        V4        V5  \\\n",
      "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
      "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
      "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
      "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
      "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...       V21       V22  \\\n",
      "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
      "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
      "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
      "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
      "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
      "...          ...       ...       ...       ...  ...       ...       ...   \n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
      "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
      "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
      "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
      "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
      "...          ...       ...       ...       ...       ...       ...     ...   \n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[284807 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. use shuffle/ randomize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2. use One-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3. use Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. use data spletting up X/y Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5. use conver data_frame to numpy arrays (float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6. use spletting the final data into X/y train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = dataf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "28802    35168.0 -1.586975  1.482836  0.698182 -0.812484 -0.221399  0.266437   \n",
      "52769    45633.0 -0.155976  0.908885  0.440577  0.438822  0.077250 -0.179268   \n",
      "76571    56631.0  1.032986 -0.156409  0.989058  1.135189 -0.782960 -0.067406   \n",
      "70248    53780.0  1.047709 -0.197146  1.341428  1.235198 -0.918804  0.457996   \n",
      "117757   74797.0  1.154096  0.220933  0.541718  1.316414 -0.220498 -0.207665   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "140963   84051.0  1.184208  0.278050  0.169056  0.448129  0.086727 -0.072693   \n",
      "142432   84713.0  1.370514 -1.512728  1.292429 -1.143470 -2.370048 -0.203858   \n",
      "123154   76830.0  1.038747  0.024090  0.597918  1.279904 -0.360380 -0.006809   \n",
      "279818  169105.0 -1.784815  1.867738 -1.150004  1.775700  2.725011  4.622162   \n",
      "74357    55535.0  0.666894 -1.100855  0.191288  0.297480 -0.660330  0.489482   \n",
      "\n",
      "              V7        V8        V9  ...       V21       V22       V23  \\\n",
      "28802  -0.168079  1.196370 -0.521889  ... -0.023868 -0.018491  0.076349   \n",
      "52769   0.217831  0.252683  0.292319  ... -0.071350  0.255070  0.062142   \n",
      "76571  -0.464886  0.164768  0.563044  ...  0.082145  0.130959  0.011107   \n",
      "70248  -0.795624  0.415110  0.752063  ...  0.021071  0.215129  0.047046   \n",
      "117757  0.006600  0.002200  0.213908  ... -0.178087 -0.371928  0.045038   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "140963 -0.050004  0.064469 -0.308067  ... -0.219336 -0.612618  0.093548   \n",
      "142432 -1.783686  0.267170 -1.003949  ... -0.193061 -0.145253  0.092649   \n",
      "123154 -0.105354  0.172839  0.054769  ... -0.103939 -0.301606  0.040780   \n",
      "279818 -0.568978  1.047406 -1.733269  ...  1.046211  0.149536 -0.081321   \n",
      "74357  -0.171147  0.316327  0.547992  ... -0.045371 -0.551437 -0.079415   \n",
      "\n",
      "             V24       V25       V26       V27       V28  Amount  Class  \n",
      "28802  -0.241722 -0.269775  0.341666  0.192945  0.098755    4.00      0  \n",
      "52769   0.158860 -0.340529  0.290302  0.351994  0.077811   12.31      0  \n",
      "76571   0.046038  0.211984 -0.413543  0.057055  0.043942   63.79      0  \n",
      "70248   0.209778  0.253302 -0.406773  0.079041  0.025223   11.50      0  \n",
      "117757  0.065463  0.453123 -0.468944  0.043758  0.023649   12.05      0  \n",
      "...          ...       ...       ...       ...       ...     ...    ...  \n",
      "140963 -0.330205  0.177324  0.124304 -0.007504  0.016176    6.78      0  \n",
      "142432  0.469385  0.118086 -0.219632  0.060270  0.022184   24.99      0  \n",
      "123154  0.195725  0.358612 -0.499563  0.029482  0.019046   41.85      0  \n",
      "279818  0.686934  0.013194  0.044958 -0.455038  0.023672   15.10      0  \n",
      "74357  -0.259941 -0.044552  0.907240 -0.096269  0.024753  244.58      0  \n",
      "\n",
      "[284807 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print (shuffled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data = pd.get_dummies(shuffled_data, columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "28802    35168.0 -1.586975  1.482836  0.698182 -0.812484 -0.221399  0.266437   \n",
      "52769    45633.0 -0.155976  0.908885  0.440577  0.438822  0.077250 -0.179268   \n",
      "76571    56631.0  1.032986 -0.156409  0.989058  1.135189 -0.782960 -0.067406   \n",
      "70248    53780.0  1.047709 -0.197146  1.341428  1.235198 -0.918804  0.457996   \n",
      "117757   74797.0  1.154096  0.220933  0.541718  1.316414 -0.220498 -0.207665   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "140963   84051.0  1.184208  0.278050  0.169056  0.448129  0.086727 -0.072693   \n",
      "142432   84713.0  1.370514 -1.512728  1.292429 -1.143470 -2.370048 -0.203858   \n",
      "123154   76830.0  1.038747  0.024090  0.597918  1.279904 -0.360380 -0.006809   \n",
      "279818  169105.0 -1.784815  1.867738 -1.150004  1.775700  2.725011  4.622162   \n",
      "74357    55535.0  0.666894 -1.100855  0.191288  0.297480 -0.660330  0.489482   \n",
      "\n",
      "              V7        V8        V9  ...       V22       V23       V24  \\\n",
      "28802  -0.168079  1.196370 -0.521889  ... -0.018491  0.076349 -0.241722   \n",
      "52769   0.217831  0.252683  0.292319  ...  0.255070  0.062142  0.158860   \n",
      "76571  -0.464886  0.164768  0.563044  ...  0.130959  0.011107  0.046038   \n",
      "70248  -0.795624  0.415110  0.752063  ...  0.215129  0.047046  0.209778   \n",
      "117757  0.006600  0.002200  0.213908  ... -0.371928  0.045038  0.065463   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "140963 -0.050004  0.064469 -0.308067  ... -0.612618  0.093548 -0.330205   \n",
      "142432 -1.783686  0.267170 -1.003949  ... -0.145253  0.092649  0.469385   \n",
      "123154 -0.105354  0.172839  0.054769  ... -0.301606  0.040780  0.195725   \n",
      "279818 -0.568978  1.047406 -1.733269  ...  0.149536 -0.081321  0.686934   \n",
      "74357  -0.171147  0.316327  0.547992  ... -0.551437 -0.079415 -0.259941   \n",
      "\n",
      "             V25       V26       V27       V28  Amount  Class_0  Class_1  \n",
      "28802  -0.269775  0.341666  0.192945  0.098755    4.00        1        0  \n",
      "52769  -0.340529  0.290302  0.351994  0.077811   12.31        1        0  \n",
      "76571   0.211984 -0.413543  0.057055  0.043942   63.79        1        0  \n",
      "70248   0.253302 -0.406773  0.079041  0.025223   11.50        1        0  \n",
      "117757  0.453123 -0.468944  0.043758  0.023649   12.05        1        0  \n",
      "...          ...       ...       ...       ...     ...      ...      ...  \n",
      "140963  0.177324  0.124304 -0.007504  0.016176    6.78        1        0  \n",
      "142432  0.118086 -0.219632  0.060270  0.022184   24.99        1        0  \n",
      "123154  0.358612 -0.499563  0.029482  0.019046   41.85        1        0  \n",
      "279818  0.013194  0.044958 -0.455038  0.023672   15.10        1        0  \n",
      "74357  -0.044552  0.907240 -0.096269  0.024753  244.58        1        0  \n",
      "\n",
      "[284807 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = (one_hot_data - one_hot_data.min()) / (one_hot_data.max() - one_hot_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "28802   0.203528  0.931333  0.782904  0.849512  0.215913  0.764226  0.265699   \n",
      "52769   0.264092  0.955644  0.776848  0.845048  0.271383  0.766236  0.261217   \n",
      "76571   0.327741  0.975843  0.765608  0.854553  0.302252  0.760445  0.262342   \n",
      "70248   0.311241  0.976093  0.765178  0.860659  0.306685  0.759531  0.267624   \n",
      "117757  0.432873  0.977900  0.769590  0.846801  0.310286  0.764232  0.260932   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "140963  0.486429  0.978412  0.770192  0.840343  0.271795  0.766300  0.262289   \n",
      "142432  0.490260  0.981577  0.751297  0.859810  0.201241  0.749761  0.260970   \n",
      "123154  0.444639  0.975941  0.767513  0.847775  0.308667  0.763290  0.262951   \n",
      "279818  0.978662  0.927972  0.786966  0.817486  0.330645  0.784061  0.309491   \n",
      "74357   0.321398  0.969623  0.755643  0.840728  0.265117  0.761271  0.267941   \n",
      "\n",
      "              V7        V8        V9  ...       V22       V23       V24  \\\n",
      "28802   0.264332  0.798219  0.444802  ...  0.509168  0.666567  0.349662   \n",
      "52769   0.266683  0.788096  0.472850  ...  0.521930  0.666356  0.403640   \n",
      "76571   0.262523  0.787153  0.482176  ...  0.516140  0.665599  0.388438   \n",
      "70248   0.260508  0.789838  0.488687  ...  0.520067  0.666132  0.410502   \n",
      "117757  0.265396  0.785409  0.470149  ...  0.492681  0.666102  0.391055   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "140963  0.265051  0.786077  0.452168  ...  0.481452  0.666823  0.337739   \n",
      "142432  0.254489  0.788251  0.428196  ...  0.503255  0.666810  0.445484   \n",
      "123154  0.264714  0.787240  0.464667  ...  0.495961  0.666039  0.408608   \n",
      "279818  0.261889  0.796621  0.403072  ...  0.517007  0.664226  0.474798   \n",
      "74357   0.264313  0.788779  0.481657  ...  0.484306  0.664254  0.347207   \n",
      "\n",
      "             V25       V26       V27       V28    Amount  Class_0  Class_1  \n",
      "28802   0.562763  0.481259  0.420072  0.315128  0.000156      1.0      0.0  \n",
      "52769   0.558792  0.472869  0.423008  0.314703  0.000479      1.0      0.0  \n",
      "76571   0.589806  0.357897  0.417564  0.314016  0.002483      1.0      0.0  \n",
      "70248   0.592125  0.359003  0.417970  0.313636  0.000448      1.0      0.0  \n",
      "117757  0.603341  0.348847  0.417319  0.313604  0.000469      1.0      0.0  \n",
      "...          ...       ...       ...       ...       ...      ...      ...  \n",
      "140963  0.587860  0.445753  0.416372  0.313452  0.000264      1.0      0.0  \n",
      "142432  0.584535  0.389572  0.417623  0.313574  0.000973      1.0      0.0  \n",
      "123154  0.598036  0.343846  0.417055  0.313510  0.001629      1.0      0.0  \n",
      "279818  0.578647  0.432792  0.408112  0.313604  0.000588      1.0      0.0  \n",
      "74357   0.575406  0.573644  0.414734  0.313626  0.009520      1.0      0.0  \n",
      "\n",
      "[284807 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = normalized_data.drop(['Class_0', 'Class_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = normalized_data[['Class_0', 'Class_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. Spletting up X/y Values\n",
    "ar_X, ar_y = np.asarray(df_X.values, dtype ='float32'), np.asarray(df_y.values, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allocate first 80% of data_frames into training data and remining 20% to testing data\n",
    "train_size = int(0.8 * len(ar_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_X_train, raw_y_train) = (ar_X[:train_size], ar_y[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_X_test, raw_y_test) = (ar_X[train_size:], ar_y[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_legit, count_fraud = np.unique(dataf['Class'], return_counts=True) [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_ratio = (count_fraud / (count_legit + count_fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of fraudulent transactions: 0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "print('Percent of fraudulent transactions:', fraud_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies a logit weighting of 578 (1/0.0017) to fraudulent transactions to cause model to pay more attention to them\n",
    "weighting = 1 / fraud_ratio\n",
    "raw_y_train[:, 1] = raw_y_train[:, 1] * weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing older version of tensorflow as new version does not support GPU on macbook.\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 cells for the input dimensions\n",
    "input_dimensions = ar_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 cells for the output dimensions \n",
    "output_dimensions = ar_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 cells for the 1st layer\n",
    "num_layer_1_cells = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 150 cells for the second layer\n",
    "num_layer_2_cells = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/youssef/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#to fix an issue with tf 2.0 \n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "#with tf.Session() as sess:\n",
    "# We will use these as inputs to the model when it comes time to train it (assign values at run time)\n",
    "X_train_node = tf.placeholder(tf.float32, [None, input_dimensions], name='X_train')\n",
    "y_train_node = tf.placeholder(tf.float32, [None, output_dimensions], name='y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use these as inputs to the model once it comes time to test it\n",
    "X_test_node = tf.constant(raw_X_test, name='X_test')\n",
    "y_test_node = tf.constant(raw_y_test, name='y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer takes in input and passes output to 2nd layer\n",
    "weight_1_node = tf.Variable(tf.zeros([input_dimensions, num_layer_1_cells]), name='weight_1')\n",
    "biases_1_node = tf.Variable(tf.zeros([num_layer_1_cells]), name='biases_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second layer takes in input from 1st layer and passes output to 3rd layer\n",
    "weight_2_node = tf.Variable(tf.zeros([num_layer_1_cells, num_layer_2_cells]), name='weight_2')\n",
    "biases_2_node = tf.Variable(tf.zeros([num_layer_2_cells]), name='biases_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third layer takes in input from 2nd layer and outputs [1 0] or [0 1] depending on fraud vs legit\n",
    "weight_3_node = tf.Variable(tf.zeros([num_layer_2_cells, output_dimensions]), name='weight_3')\n",
    "biases_3_node = tf.Variable(tf.zeros([output_dimensions]), name='biases_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run an input tensor through the 3 layers and output a tensor that will give us a fraud/legit result\n",
    "# Each layer uses a different function to fit lines through the data and predict whether a given input tensor will \\\n",
    "#   result in a fraudulent or legitimate transaction\n",
    "def network(input_tensor):\n",
    "    # Sigmoid fits modified data well\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(input_tensor, weight_1_node) + biases_1_node)\n",
    "    # Dropout prevents model from becoming lazy and over confident\n",
    "    layer2 = tf.nn.dropout(tf.nn.sigmoid(tf.matmul(layer1, weight_2_node) + biases_2_node), 0.85)\n",
    "    # Softmax works very well with one hot encoding which is how results are outputted\n",
    "    layer3 = tf.nn.softmax(tf.matmul(layer2, weight_3_node) + biases_3_node)\n",
    "    return layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-36-7127a61d0022>:8: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Used to predict what results will be given training or testing input data\n",
    "# Remember, X_train_node is just a placeholder for now. We will enter values at run time\n",
    "y_train_prediction = network(X_train_node)\n",
    "y_test_prediction = network(X_test_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy loss function measures differences between actual output and predicted output\n",
    "cross_entropy = tf.losses.softmax_cross_entropy(y_train_node, y_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer function will try to minimize loss (cross_entropy) but changing the 3 layers' variable values at a\n",
    "#   learning rate of 0.005\n",
    "optimizer = tf.train.AdamOptimizer(0.005).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of the actual result vs the predicted result\n",
    "def calculate_accuracy(actual, predicted):\n",
    "    actual = np.argmax(actual, 1)\n",
    "    predicted = np.argmax(predicted, 1)\n",
    "    return (100 * np.sum(np.equal(predicted, actual)) / predicted.shape[0])\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Current loss: 1.3964 Elapsed time: 1.08 seconds\n",
      "Current accuracy: 0.16%\n",
      "Epoch: 10 Current loss: 1.3954 Elapsed time: 0.67 seconds\n",
      "Current accuracy: 95.14%\n",
      "Epoch: 20 Current loss: 1.3680 Elapsed time: 0.78 seconds\n",
      "Current accuracy: 62.17%\n",
      "Epoch: 30 Current loss: 1.2578 Elapsed time: 0.66 seconds\n",
      "Current accuracy: 89.03%\n",
      "Epoch: 40 Current loss: 1.0910 Elapsed time: 0.67 seconds\n",
      "Current accuracy: 97.14%\n",
      "Epoch: 50 Current loss: 0.9695 Elapsed time: 0.78 seconds\n",
      "Current accuracy: 99.04%\n",
      "Epoch: 60 Current loss: 0.9023 Elapsed time: 0.68 seconds\n",
      "Current accuracy: 99.61%\n",
      "Epoch: 70 Current loss: 0.8751 Elapsed time: 0.70 seconds\n",
      "Current accuracy: 99.74%\n",
      "Epoch: 80 Current loss: 0.8565 Elapsed time: 0.84 seconds\n",
      "Current accuracy: 99.62%\n",
      "Epoch: 90 Current loss: 0.8392 Elapsed time: 0.74 seconds\n",
      "Current accuracy: 99.46%\n",
      "Final accuracy: 99.56%\n",
      "Final fraud specific accuracy: 80.43%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        _, cross_entropy_score = session.run([optimizer, cross_entropy],\n",
    "                                             feed_dict={X_train_node: raw_X_train, y_train_node: raw_y_train})\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            timer = time.time() - start_time\n",
    "\n",
    "            print('Epoch: {}'.format(epoch), 'Current loss: {0:.4f}'.format(cross_entropy_score),\n",
    "                  'Elapsed time: {0:.2f} seconds'.format(timer))\n",
    "\n",
    "            final_y_test = y_test_node.eval()\n",
    "            final_y_test_prediction = y_test_prediction.eval()\n",
    "            final_accuracy = calculate_accuracy(final_y_test, final_y_test_prediction)\n",
    "            print(\"Current accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "    final_y_test = y_test_node.eval()\n",
    "    final_y_test_prediction = y_test_prediction.eval()\n",
    "    final_accuracy = calculate_accuracy(final_y_test, final_y_test_prediction)\n",
    "    print(\"Final accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "final_fraud_y_test = final_y_test[final_y_test[:, 1] == 1]\n",
    "final_fraud_y_test_prediction = final_y_test_prediction[final_y_test[:, 1] == 1]\n",
    "final_fraud_accuracy = calculate_accuracy(final_fraud_y_test, final_fraud_y_test_prediction)\n",
    "print('Final fraud specific accuracy: {0:.2f}%'.format(final_fraud_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completed..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
